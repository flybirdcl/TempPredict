{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26601b0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 12:30:52.885472: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-16 12:30:52.938139: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-16 12:30:52.938821: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-16 12:30:53.803701: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c7c2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Vancouver', 'Portland', 'San Francisco', 'Seattle', 'Los Angeles',\n",
       "       'San Diego', 'Las Vegas', 'Phoenix', 'Albuquerque', 'Denver',\n",
       "       'San Antonio', 'Dallas', 'Houston', 'Kansas City', 'Minneapolis',\n",
       "       'Saint Louis', 'Chicago', 'Nashville', 'Indianapolis', 'Atlanta',\n",
       "       'Detroit', 'Jacksonville', 'Charlotte', 'Miami', 'Pittsburgh',\n",
       "       'Toronto', 'Philadelphia', 'New York', 'Montreal', 'Boston',\n",
       "       'Beersheba', 'Tel Aviv District', 'Eilat', 'Haifa', 'Nahariyya',\n",
       "       'Jerusalem'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t = pd.read_csv('temperature.csv',index_col=0)\n",
    "df_h = pd.read_csv('humidity.csv',index_col=0)\n",
    "df_p = pd.read_csv('pressure.csv',index_col=0)\n",
    "df_w = pd.read_csv('wind_speed.csv',index_col=0)\n",
    "df_h.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7d819b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    data_mean = data.mean(axis=0)\n",
    "    data_std = data.std(axis=0)\n",
    "    return (data - data_mean) / data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc6578d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>presure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-10-01 13:00:00</th>\n",
       "      <td>291.530000</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-01 14:00:00</th>\n",
       "      <td>291.533501</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-01 15:00:00</th>\n",
       "      <td>291.543355</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-01 16:00:00</th>\n",
       "      <td>291.553209</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-01 17:00:00</th>\n",
       "      <td>291.563063</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 20:00:00</th>\n",
       "      <td>292.150000</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 21:00:00</th>\n",
       "      <td>292.740000</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 22:00:00</th>\n",
       "      <td>292.580000</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 23:00:00</th>\n",
       "      <td>292.610000</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30 00:00:00</th>\n",
       "      <td>291.400000</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44899 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     temperature  presure  humidity  wind\n",
       "datetime                                                 \n",
       "2012-10-01 13:00:00   291.530000   1013.0      82.0   0.0\n",
       "2012-10-01 14:00:00   291.533501   1013.0      81.0   0.0\n",
       "2012-10-01 15:00:00   291.543355   1013.0      81.0   0.0\n",
       "2012-10-01 16:00:00   291.553209   1013.0      81.0   0.0\n",
       "2012-10-01 17:00:00   291.563063   1013.0      80.0   0.0\n",
       "...                          ...      ...       ...   ...\n",
       "2017-11-29 20:00:00   292.150000   1017.0      72.0   2.0\n",
       "2017-11-29 21:00:00   292.740000   1017.0      72.0   1.0\n",
       "2017-11-29 22:00:00   292.580000   1016.0      68.0   2.0\n",
       "2017-11-29 23:00:00   292.610000   1016.0      63.0   2.0\n",
       "2017-11-30 00:00:00   291.400000   1017.0      72.0   2.0\n",
       "\n",
       "[44899 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city = 'San Diego'\n",
    "tempog = df_t[city]\n",
    "temp = df_t[city].rename(\"temperature\").to_frame(name='temperature')\n",
    "humid = df_h[city].rename(\"humidity\").to_frame(name='humidity')\n",
    "press = df_p[city].rename(\"presure\").to_frame(name='presure')\n",
    "wind = df_w[city].rename(\"wind\").to_frame(name='wind')\n",
    "\n",
    "\n",
    "features = pd.concat([temp, press, humid, wind], axis=1)\n",
    "# features.index = time\n",
    "features = features.dropna()\n",
    "features\n",
    "\n",
    "featuresog = features\n",
    "featuresog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41c9df9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23627539, -0.58110974,  0.73378908, -1.15167403],\n",
       "       [ 0.23685282, -0.58110974,  0.68310075, -1.15167403],\n",
       "       [ 0.23847809, -0.58110974,  0.68310075, -1.15167403],\n",
       "       ...,\n",
       "       [ 0.40945551, -0.24393192,  0.02415242,  0.24995504],\n",
       "       [ 0.41440351, -0.24393192, -0.22928924,  0.24995504],\n",
       "       [ 0.21483404, -0.13153931,  0.22690575,  0.24995504]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_size = int ( 0.8 * features.shape[0])  \n",
    "\n",
    "dataset=features.values\n",
    "data_mean = dataset[:training_size].mean(axis=0)\n",
    "data_std = dataset[:training_size].std(axis=0)\n",
    "dataset = (dataset-data_mean)/data_std\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c006d70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222888</td>\n",
       "      <td>-0.528665</td>\n",
       "      <td>0.731908</td>\n",
       "      <td>-1.181374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.223482</td>\n",
       "      <td>-0.528665</td>\n",
       "      <td>0.680392</td>\n",
       "      <td>-1.181374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.225155</td>\n",
       "      <td>-0.528665</td>\n",
       "      <td>0.680392</td>\n",
       "      <td>-1.181374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.226829</td>\n",
       "      <td>-0.528665</td>\n",
       "      <td>0.680392</td>\n",
       "      <td>-1.181374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.228502</td>\n",
       "      <td>-0.528665</td>\n",
       "      <td>0.628876</td>\n",
       "      <td>-1.181374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44894</th>\n",
       "      <td>0.328173</td>\n",
       "      <td>-0.061829</td>\n",
       "      <td>0.216750</td>\n",
       "      <td>0.162904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44895</th>\n",
       "      <td>0.428364</td>\n",
       "      <td>-0.061829</td>\n",
       "      <td>0.216750</td>\n",
       "      <td>-0.509235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44896</th>\n",
       "      <td>0.401194</td>\n",
       "      <td>-0.178538</td>\n",
       "      <td>0.010687</td>\n",
       "      <td>0.162904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44897</th>\n",
       "      <td>0.406288</td>\n",
       "      <td>-0.178538</td>\n",
       "      <td>-0.246892</td>\n",
       "      <td>0.162904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44898</th>\n",
       "      <td>0.200812</td>\n",
       "      <td>-0.061829</td>\n",
       "      <td>0.216750</td>\n",
       "      <td>0.162904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44899 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3\n",
       "0      0.222888 -0.528665  0.731908 -1.181374\n",
       "1      0.223482 -0.528665  0.680392 -1.181374\n",
       "2      0.225155 -0.528665  0.680392 -1.181374\n",
       "3      0.226829 -0.528665  0.680392 -1.181374\n",
       "4      0.228502 -0.528665  0.628876 -1.181374\n",
       "...         ...       ...       ...       ...\n",
       "44894  0.328173 -0.061829  0.216750  0.162904\n",
       "44895  0.428364 -0.061829  0.216750 -0.509235\n",
       "44896  0.401194 -0.178538  0.010687  0.162904\n",
       "44897  0.406288 -0.178538 -0.246892  0.162904\n",
       "44898  0.200812 -0.061829  0.216750  0.162904\n",
       "\n",
       "[44899 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = normalize(features.values)\n",
    "features = pd.DataFrame(features)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acde0e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "366d8215",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_history = 48\n",
    "future_target = 48\n",
    "STEP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3658a2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
    "#                       target_size, step, single_step=False):\n",
    "#   data = []\n",
    "#   labels = []\n",
    "\n",
    "#   start_index = start_index + history_size\n",
    "#   if end_index is None:\n",
    "#     end_index = len(dataset) - target_size\n",
    "\n",
    "#   for i in range(start_index, end_index):\n",
    "#     indices = range(i-history_size, i, step)\n",
    "#     data.append(dataset[indices])\n",
    "\n",
    "#     if single_step:\n",
    "#       labels.append(target[i+target_size])\n",
    "#     else:\n",
    "#       labels.append(target[i:i+target_size])\n",
    "\n",
    "#   return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a6ec1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_multi, y_train_multi = multivariate_data(dataset, dataset[:, 1], 0,\n",
    "#                                                  training_size, past_history,\n",
    "#                                                  future_target, STEP)\n",
    "# x_val_multi, y_val_multi = multivariate_data(dataset, dataset[:, 1],\n",
    "#                                              training_size, None, past_history,\n",
    "#                                              future_target, STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a12f50e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ('Single window of past history : {}'.format(x_train_multi[0].shape))\n",
    "# print ('\\n Target temperature to predict : {}'.format(y_train_multi[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac64084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "892b37ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features 4\n"
     ]
    }
   ],
   "source": [
    "# ighnore below\n",
    "dataset = featuresog.values\n",
    "dataset = dataset.astype('float32')\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "#print('dataset.shape', dataset.shape)\n",
    "num_of_features = len(features.columns)\n",
    "print('Number of features', num_of_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ad5a9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 12:30:55.350145: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 12:30:55.619171: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-16 12:30:55.620796: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-16 12:30:55.622110: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-16 12:30:56.003681: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-16 12:30:56.005518: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-16 12:30:56.007010: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-16 12:30:56.713959: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-16 12:30:56.715773: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-16 12:30:56.717242: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/197 [============================>.] - ETA: 0s - loss: 0.0212"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 12:31:08.489064: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-16 12:31:08.490853: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-16 12:31:08.492226: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197/197 [==============================] - 15s 66ms/step - loss: 0.0212 - val_loss: 0.0218\n",
      "Epoch 2/5\n",
      "197/197 [==============================] - 12s 63ms/step - loss: 0.0086 - val_loss: 0.0176\n",
      "Epoch 3/5\n",
      "197/197 [==============================] - 12s 63ms/step - loss: 0.0045 - val_loss: 0.0116\n",
      "Epoch 4/5\n",
      "197/197 [==============================] - 12s 63ms/step - loss: 0.0039 - val_loss: 0.0157\n",
      "Epoch 5/5\n",
      "197/197 [==============================] - 13s 64ms/step - loss: 0.0038 - val_loss: 0.0166\n"
     ]
    }
   ],
   "source": [
    "epochs=5\n",
    "lstm_layers = 128\n",
    "look_back = 24*3\n",
    "num_of_features=4\n",
    "batch_size=128\n",
    "\n",
    "train_size_percent = 0.80\n",
    "pred_col = featuresog.columns.get_loc(\"temperature\")\n",
    "print(pred_col)\n",
    "\n",
    "# function to split the data\n",
    "def create_dataset(dataset, pred_col, look_back=1):\n",
    "  dataX, dataY = [], []\n",
    "  for i in range(len(dataset)-look_back-1):\n",
    "    a = dataset[i:(i+look_back), :]\n",
    "    dataX.append(a)\n",
    "    dataY.append(dataset[i + look_back, pred_col])\n",
    "  return np.array(dataX), np.array(dataY)\n",
    "\n",
    "\n",
    "train_size = int(len(dataset) * train_size_percent)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]\n",
    "\n",
    "trainX, trainY = create_dataset(train, pred_col, look_back=look_back)\n",
    "testX, testY = create_dataset(test, pred_col, look_back=look_back)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(lstm_layers, input_shape=(look_back,num_of_features)))\n",
    "model.add(Dense(future_target))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history= model.fit(trainX, trainY,validation_split=0.30, epochs=epochs, batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3e599d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "   1/1121 [..............................] - ETA: 7:36"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 12:32:00.826587: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-16 12:32:00.828310: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-16 12:32:00.829685: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1121/1121 [==============================] - 14s 13ms/step\n",
      "279/279 [==============================] - 3s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77635da8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=(35846, 72, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(trainPredict)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mambaforge/envs/cs152/lib/python3.10/site-packages/pandas/core/frame.py:721\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    711\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    712\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    713\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    719\u001b[0m         )\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 721\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m/opt/mambaforge/envs/cs152/lib/python3.10/site-packages/pandas/core/internals/construction.py:329\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    324\u001b[0m         values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;66;03m# by definition an array here\u001b[39;00m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;66;03m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_prep_ndarraylike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_on_sanitize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dtype_equal(values\u001b[38;5;241m.\u001b[39mdtype, dtype):\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;66;03m# GH#40110 see similar check inside sanitize_array\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     rcf \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m (is_integer_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/mambaforge/envs/cs152/lib/python3.10/site-packages/pandas/core/internals/construction.py:583\u001b[0m, in \u001b[0;36m_prep_ndarraylike\u001b[0;34m(values, copy)\u001b[0m\n\u001b[1;32m    581\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mreshape((values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust pass 2-d input. shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\u001b[0;31mValueError\u001b[0m: Must pass 2-d input. shape=(35846, 72, 4)"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(trainPredict)\n",
    "pd.DataFrame(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e156b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get something which has as many features as dataset\n",
    "testPredict_extended = np.zeros((len(testPredict),num_of_features))\n",
    "# Put the predictions there\n",
    "testPredict_extended[:,pred_col] = testPredict[:,0]\n",
    "# Inverse transform it and select the pred_col column.\n",
    "testPredict = scaler.inverse_transform(testPredict_extended)[:,pred_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9569a6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "trainY_extended = np.zeros((len(trainY),num_of_features))\n",
    "trainY_extended[:,pred_col]=trainY\n",
    "trainY = scaler.inverse_transform(trainY_extended)[:,pred_col]\n",
    "\n",
    "testY_extended = np.zeros((len(testY),num_of_features))\n",
    "testY_extended[:,pred_col]=testY\n",
    "testY = scaler.inverse_transform(testY_extended)[:,pred_col]\n",
    "\n",
    "plt.plot(trainY, label = \"line 1\")\n",
    "print(trainPredict)\n",
    "print(trainY)\n",
    "# plt.plot(range(0,len(trainPredict)),trainPredict, label = \"line 2\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(trainPredict, label = \"line 1\")\n",
    "# plt.plot(range(0,len(trainPredict)),trainPredict, label = \"line 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08af3448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_steps(length):\n",
    "  return list(range(-length, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca2a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y in val_data_multi.take(5):\n",
    "#   multi_step_plot(x[0], y[0], multi_step_model.predict(x)[0])\n",
    "\n",
    "for x, y in val_data_multi.take(5):\n",
    "  multi_step_plot(x[0], y[0], model.predict(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b173c41c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686c4a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9b7a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
